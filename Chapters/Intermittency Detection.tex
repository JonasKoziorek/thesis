\chapter{Intermittency Detection}
\label{chapter:intdetection}
Section \ref{sec:ambiguous_bif_diag} of the previous chapter introduced the problem of ambiguity of the bifurcation diagram.
This chapter introduces an algorithm that aims to detect the ambiguity.
The algorithm consists of 3 core parts.

\begin{enumerate}
	\item \textbf{Global Search} -- searching for areas where breakpoints occur.
	\item \textbf{Local Search} -- searching for precise locations of breakpoints.
	\item \textbf{Coloring} -- coloring the bifurcation diagram in the proximity of breakpoints.
\end{enumerate}

Each of these parts are described in the following sections.
The last section of this chapter combines all the parts together.

\section{Global Search}
\label{sec:globsearch}
\textcolor{darkred}{
The initial phase of the algorithm, which shall be called the Global Search, aims to find approximate parameter intervals in which type-I intermittency occurs.
The algorithm searches through the whole parameter space globally to find these intervals.
More specifically, the search for type-I intermittency regions is equivalent to a search for the breakpoints in the bifurcation diagram.
Global Search consists of two parts - Naive Global Search and detection of periodic points.
These two parts are described in the following sections and then combined together.
}
\subsection{Naive Global Search}

\textcolor{darkred}{
A breakpoint is a parameter value at which the bifurcation diagram transitions from nonperiodic behavior to periodic behavior.
Such breakpoint can be seen in Figure~\ref{fig:break_point_search_example}.
The Figure shows that there is nonperiodic behavior to the left of the breakpoint and periodic behavior to the right of it.
With this knowledge, each breakpoint can be identified by a unique number $n$ which corresponds to $n$ periodic behavior to the right of it.
If the parameter space could be searched through and the period of the system for each parameter value could be determined, the breakpoints could be easily found.
To do that, an algorithm is needed to determine the period of the system for any given parameter value.
}
\par
\textcolor{darkred}{
Let $(X, f_{p})$ be a DDS. Suppose a bifurcation diagram of $f_{p}$ is constructed for some $x_0$, $n_{total}$, $n_{last}$ and $p_{range}$ (see Algorithm~\ref{alg:bif_diag}).
The fact that bifurcation diagram shows $n$-periodic behavior ($n$ dots) for a parameter $p$ implies that map $f_{p}$ is $n$-periodic or eventually $n$-periodic.
Two situations can happen:
\begin{enumerate}
    \item Map $f_{p}$ has a stable periodic orbit and the $x_0$ has converged to it in $n_{total}-n_{last}$ iterations.
    \item Initial condition $x_0$ belongs to a UPO or SPO of $f_p$.
\end{enumerate}
When talking about periodic behavior in a bifurcation diagram, the focus will be on case $1$.
Case $2$ will be disregarded since it is not very probable that an initial condition will belong to a periodic orbit.
}
\par
\textcolor{darkred}{
Theorem~\ref{theorem:single_orbit} states that the Logistic map $\mathcal{L}_r$ can only have at most one unique stable $n$-periodic orbit for each parameter $r$.
Hence, if bifurcation diagram exhibits $n$-periodic behavior at $r$, it can be concluded that $\mathcal{L}_{r}$ has an $n$-periodic SPO.
Consequently, finding the smallest SPO of $\mathcal{L}_{r}$ would indicate how many dots there are in the bifurcation diagram at $r$.
}
\par
\textcolor{darkred}{
There exist algorithms for finding the UPO (and thus SPO) of an arbitrary DDS.
They will be discussed in detail in Subsection~\ref{subsec: detection_of_periodic_points}.
Although they are efficient, they are not efficient enough for the current goal.
The aim is to search through the whole parameter space $p_{range}$ and try to detect an SPO for every parameter $p \in p_{range}$.
}
\par
\textcolor{darkred}{
A naive approach to determine whether $p$ is $n$-periodic is to check whether $f^{m}_{p}(x) = f^{m+n}_{p}(x)$ where $m = n_{total}-n_{last}$.
If $n$ is the smallest number for which the equality holds, then $x$ is an $n$-periodic point.
Consequently, the bifurcation diagram has $n$ dots at $p$.
If the equality is checked for $n = 1,2,\dots,o$ in an ascending order, then it is clear which $n$ is the smallest.
Note that $o$ is some maximal period which is checked.
}
\par
\textcolor{darkred}{
The procedure that was just described shall be called Naive Global Search (NGS).
NGS is a quick way to estimate periodicity in the bifurcation diagram for any parameter $p$.
The pseudocode for this procedure is presented in Algorithm~\ref{alg:naive_global_search}.
The result of NGS is portrayed graphically in Figure~\ref{fig:naive_global_search}.
There, the points that were identified by NGS as periodic are colored blue.
}
\par
\textcolor{darkred}{
After applying NGS, the breakpoint can found easily.
It can be concluded that the breakpoint occurs between parameters $[p_{A}, p_{B}]$ such that NGS found no periodicity for $p_{A}$ and $n$-periodicity for $p_{B}$.
However, the shortcoming of NGS is that it is deceiving in the proximity of a breakpoint.
Imagine that $f^{m}_{p}(x_0)$ for $m = n_{total}-n_{last}$ lies in the laminar phase of an intermittent trajectory of $f_{p}$.
Then $p$ will be determined as periodic even though it is not.
In addition, the bifurcation diagram at $p$ might or might not show $n$ dots.
Since $\mathcal{T}_{m}^{n_{total}}(f_{p}, x_{0})$ is intermittent, the bifurcation diagram could show band of point of just $n$ dots.
That depends on whether the trajectory subset is in the laminar or turbulent phase.
}
\par
\textcolor{darkred}{
To overcome this issue, it is useful to verify that period of $p_{A}$ and $p_{B}$ was estimated correctly.
The next subsection introduces efficient algorithms for computing UPO of arbitrary DDS.
By checking how many periodic points are stable for $f_{p_{A}}$ and $f_{p_{B}}$, period of $p_{A}$ and $p_{B}$ can be verified.
}

\begin{algorithm}[!h]
    \caption{Naive Global Search}
    \label{alg:naive_global_search}
    \begin{algorithmic}[1]
        \Statex $f \gets$ map
        \Statex $p_{A} \gets$ left boundary of the parameter space
        \Statex $p_{B} \gets$ right boundary of the parameter space
        \Statex $n \gets$ number of samples in the parameter space
        \Statex $m \gets$ number of iterations
        \Statex $o \gets$ maximum period to check
        \Statex $x_0 \gets$ initial condition
        \State $p \gets p_{A}$
        \State $p_{step} \gets \frac{p_{B} - p_{A}}{n}$
        \While{$p \leq p_{B}$}
            \State $x_1 \gets f_{p}^{m}(x_0)$
            \For{$i \gets 1$ to $o$}
                \State $x_2 \gets f_{p}^{i}(x_1)$
                \If{$x_2 = x_1$}
                    \State $f_p$ is $i$-periodic
                \EndIf
            \EndFor
            \State $p \gets p + p_{step}$
        \EndWhile
    \end{algorithmic}
\end{algorithm}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{Figures/naive_global_search.png}
    \caption{
        \textcolor{darkred}{
        NGS of $\mathcal{L}_{r}$.
        Grey points: bifurcation diagram constructed of trajectories $\mathcal{T}_{3500}^{4000}(\mathcal{L}_{r}, 0.5)$ for $r \in [3.55, 3.75]$.
        Blue points: points identified as periodic. 
        Parameters of Algorithm~\ref{alg:naive_global_search}: $f = \mathcal{L}_{r}$, $p_{A} = 3.55$, $p_{B} = 3.75$, $n=5000$, $m=1800$, $o=40$ and $x_0 = 0.5$.
        }
    }
    \label{fig:naive_global_search}
\end{figure}

\subsection{Detection of Periodic Points}
\label{subsec: detection_of_periodic_points}

\textcolor{darkred}{
Detecting periodic points numerically can be approached in a straightforward manner.
An $n$-periodic point is a fixed point of the $n$-th iterate of a map.
Hence, finding roots of $f^{n}_{p}(x)-x = 0$ yields all periodic points $x$ of $n$-th iteration of map $f_{p}$.
Standard root-finding algorithms such as Newton-Raphson can be applied on function $g(x) = f^{n}(x)-x$ to find its roots.
Newton-Raphson algorithm converges to a single root. To ensure that all roots were found, the search space can be sampled to $N$ seeds.
Seeds can be created for example as a uniform grid of the search space.
Detecting roots when $n$ is relatively low is successful with proper seeding, however as $n$ increases, the number of roots increases exponentially \cite{Davidchack1999}.
As the number of roots increases, the need for finer and finer seeding arises.
With the rising number of seeds, the algorithm becomes computationally very expensive.
Another issue with Newton-Raphson is that the basins of convergence to each respective root are not very big \cite{Davidchack1999}.
}
\par
\textcolor{darkred}{
To overcome the issues with standard root-finding algorithms, researchers came up with new strategies to detect periodic points.
The central idea of the new approach is to use stabilizing transformations.
A set of transformations is proposed such that these transformations stabilize some of the fixed points so that they become attractive.
Afterwards, an iterative scheme is introduced which converges to these fixed points.
Schmelcher and Diakonos~\cite{Schmelcher1997,Pingel2000, Pingel2001} were the first to come up with the idea of stabilizing transformations.
Their algorithm is globally convergent and detects all periodic points of low periods.
The main problem with their approach is that the number of stabilizing transformation grows rapidly with increasing dimension of the dynamical system.
Another issue is that the algorithm relies on fine seeding the same way Newton-Raphson does, although it usually needs much less seeds.
}
\par
\textcolor{darkred}{
The algorithm of Schmelcher and Diakonos was subsequently improved by Davidchack and Lai (DL)~\cite{Davidchack1999, Davidchack2001, Klebanoff2001}.
They introduced two improvements: smarter seeding procedure and improved iterative scheme with enhanced convergence speed.
Through their modifications, they were able to detect periodic points of higher periods than it was previously possible.
However, their method is still not very applicable to high dimensional dynamical systems.
}
\par
\textcolor{darkred}{
Davidchack's and Lai's algorithm was futher improved by Davidchack's PhD student Crofts~\cite{Crofts2005,Crofts2007,Crofts2008,Crofts20090901}.
His version proposes smaller set of stabilizing transformations such that the method can be used for high dimensional dynamical systems.
}
\par
\textcolor{darkred}{
Another approach was proposed by Bu-Wang-Jiang (BWJ)~\cite{Bu2004}.
This approach is not based on stabilizing transformation, but on an iterative scheme together with fine seeding.
}
\par
\textcolor{darkred}{
For the purposes of the Global Search, Bu-Wang-Jiang is chosen for detection of periodic points.
It is easy to implement and it works well enough.
Pseudocode for this algorithm is presented in Algorithm~\ref{alg:bwj}.
}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{Figures/upo_search_example.png}
    \caption{
        \textcolor{darkred}{
        Detection of the fixed point of $\mathcal{L}_{r}^{6}$ for $r = 3.7$ using the DL algorithm.
        }
    }
    \label{fig:upo_search_example}
\end{figure}

\begin{algorithm}[!h]
    \caption{Bu-Wang-Jiang (BWJ)}
    \label{alg:bwj}
    \begin{algorithmic}[1]
        \Statex $f \gets$ map
        \Statex $p \gets$ period
        \Statex $seeds \gets$ seeds
        \Statex $maxiter \gets$ maximum number of iterations
        \Statex $tol \gets$ tolerance for determining a fixed point
        \For{each s in seeds}
            \State $\textbf{x}_{0} \gets s$
            \While{current iteration $< maxiter$}
                \State $J(\textbf{x}_{0}) = \partial f^{p}(\textbf{x}_{0}) / \partial \textbf{x}$ is the Jacobian at $\textbf{x}_{0}$
                \State $Q \gets (cI-J(\textbf{x}_{0}))(J(\textbf{x}_{0})-I)^{-1}$ where $I$ is identity matrix, $c \in (-1, 1)$ is a constant 
                \State $\textbf{x}_1 \gets f^{p}(\textbf{x}_{0}) + Q(f(\textbf{x}_{0})^{p}-\textbf{x}_{0})$
                \If{$\norm{f^{p}(\textbf{x}_1)-\textbf{x}_1} < tol$}
                    \State $\textbf{x}_{1}$ is a fixed point of $f^{p}$
                \EndIf
                \State $\textbf{x}_{0} \gets \textbf{x}_{1}$
            \EndWhile
        \EndFor
    \end{algorithmic}
\end{algorithm}

\textcolor{darkred}{
Note that the $seeds$ parameter in Algorithm~\ref{alg:bwj} is a set of initial conditions from which the algorithm starts.
This parameter can be generated by uniformly sampling the search space.
In case of $\mathcal{L}_{r}$, the interval $[0, 1]$ can be uniformly sampled to $N$ points.
}

\bigskip
\textcolor{darkred}{
This section has introduced an algorithm for performing a search for breakpoints in the parameter space.
First, discretization of the parameter space is performed, and the NGS is used to approximate periodicity of each parameter.
Afterwards, neighboring pairs of parameters $p_{A}$ and $p_{B}$ such that $p_{A}$ is nonperiodic and $p_{B}$ is periodic are chosen.
BWJ algorithm is used to verify that periodicity of $p_{A}$ and $p_{B}$ is correct.
If so, it is concluded that there is a breakpoint in a bifurcation diagram somewhere in the interval $[p_{A}, p_{B}]$.
At the end of the algorithm, approximate intervals $[p_{A}, p_{B}]$ and periods of $p_{B}$ are known for each breakpoint.
This algorithm is called the Global Search.
The approximate breakpoint locations evaluated by this algorithm are shown in Figure~\ref{fig:bif_diag_search_example}.
}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{Figures/bif_diag_search_example.png}
    \caption{
        \textcolor{darkred}{
        Global search of $\mathcal{L}_{r}$.
        The bifurcation diagram consists of projections of $\mathcal{T}_{900}^{1000}(\mathcal{L}_{r}, 0.5)$.
        Red lines: detected breakpoints up to period $16$.
        }
    }
    \label{fig:bif_diag_search_example}
\end{figure}

\section{Local Search}

The previous section introduced a so-called Global search, an approach to find approximate intervals in the parameter space where a breakpoint occurs.
This section introduces an algorithm to find the exact location of each breakpoint.
These locations will be later used to color the bifurcation diagram in the proximity of the breakpoint.
\par
This section discusses three algorithms for the Local search - Naive Local Search, Nested-Layer Particle Swarm Optimization and Local Search using Global Optimization.
The global search has already identified two boundaries $(p_A, p_B)$, period of the system with parameter $p_B$ and the fact that there is a breakpoint between $(p_A, p_B)$.
Subsequently, a better approximation of the parameter at which the breakpoint occurs is needed.
The three algorithms are able to approximate the parameter using the information from the Global Search.
All three algorithms solve the problem, but they use different approaches.

\subsection{Naive Local Search}
\label{subsec:naive_local_search}
The fundamental idea behind Naive Local Search (NLS) is similar to the one used in global search.
Parameter space will be searched through, and the period of the system for each parameter value will be determined.
However, instead of performing the search for the entire parameter space, the search will be performed only in the intervals found in the global search.
These intervals are special because several facts about them are known.
Their left boundary is non-periodic, and their right boundary is periodic of some period $n$.
The $n$ is known from the global search.
The goal is to push the left boundary close to the left side of the breakpoint and the right boundary close to the right side of the breakpoint.
An example of the NLS is shown in Figure~\ref{fig:break_point_search_example}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{Figures/break_point_search_example.png}
    \caption{
        \textcolor{darkred}{
        Naive Local Search of $\mathcal{L}_{r}$ for $r \in [ 3.825, 3.83 ]$.
        The bifurcation diagram consists of projections of $\mathcal{T}_{900}^{1000}(\mathcal{L}_{r}, 0.5)$.
        Red lines: Left and right estimates of the period $3$ breakpoint.
        Left estimate is found using Algorithm~\ref{alg:local_search} with parameters $p_A = 3.825$, $p_B = 3.83$, $n = 3$ and $maxiter = 20$.
        Right estimate is found analogically.
        }
    }
    \label{fig:break_point_search_example}
\end{figure}



\par
Firstly the left boundary is searched.
It is desirable to get it as close to the breakpoint as possible.
To do this combination of BWJ algorithm and a binary search is used.
For each parameter $p$ in the interval $(p_{A}, p_{B})$ identified during the global search a check whether $f_{p}$ is $n$-periodic or not is performed.
That determines whether the breakpoint is on the left or right side of the parameter.
\textcolor{darkred}{In the beginning the interval is halved to obtain two intervals, $[p_{A}, \frac{p_{A}+p_{B}}{2}]$ and $[\frac{p_{A}+p_{B}}{2}, p_{B}]$.}
If $\frac{p_{A}+p_{B}}{2}$ is $n$-periodic then it is known that the breakpoint is in the interval $[\frac{p_{A}+p_{B}}{2}, p_{B}]$.
If $\frac{p_{A}+p_{B}}{2}$ is non-periodic then it is known that the breakpoint is in the interval $[p_{A}, \frac{p_{A}+p_{B}}{2}]$.
Using the new interval the same process is repeated recursively.
The halving process is repeated for some desired number of iterations $maxiter$.
Pseudocode for the NLS of the left boundary is given in Algorithm~\ref{alg:local_search}.

\begin{algorithm}[!h]
    \caption{NLS - left boundary}
    \label{alg:local_search}
    \begin{algorithmic}[1]
        \Statex $f \gets$ map
        \Statex $p_{A} \gets$ left boundary of the parameter space
        \Statex $p_{B} \gets$ right boundary of the parameter space
        \Statex $n \gets$ period of $f{p_{B}}$
        \Statex $maxiter \gets$ number of iterations
        \State $p_{C} \gets \frac{p_{A}+p_{B}}{2}$
        \State $i \gets$ current iteration
        \If{$i = maxiter$}
            \State left boundary of the breakpoint is $p_{A}$
        \EndIf
        \If{$f_{p_{C}}$ is $n$-periodic}
            \State repeat the algorithm with the same arguments except $p_{B} \gets p_{C}$ and $i \gets i+1$
        \Else
            \State repeat the algorithm with the same arguments except $p_{A} \gets p_{C}$ and $i \gets i+1$
        \EndIf
    \end{algorithmic}
\end{algorithm}

\par
The Algorithm~\ref{alg:local_search} searches only for left boundary. Search for right boundary can be done analogically by reversing the direction of the search.
The complete NLS is both the search of the left boundary and the search of the right boundary.
These two boundaries approximate precise location of a breakpoint.
By calculating the average $p_{avg}$ of the left and right boundary, a good approximation of the parameter at which the breakpoint occurs is obtained.

\subsection{Nested-Layer Particle Swarm Optimization}
This subsection describes an alternative to the NLS algorithm.
It achieves the same goal as the NLS, but uses a different approach.
This is done by reformulating the original problem as an optimization problem.
\par
The NLS introduced in the previous subsection approximates the parameter at which the breakpoint occurs.
It is based on the idea of a binary search.
However, the search for the breakpoint can be rephrased as a search for a parameter where saddle-node bifurcation occurs.
Matsushita, Kurokawa, and Kousaka~\cite{Matsushita2019} introduced an approach to search for saddle-node bifurcation of a DDS.
Their method uses the Nested-Layer Particle Swarm Optimization (NLPSO) method.
They have previously used the same approach to detect period-doubling bifurcations of a DDS~\cite{Matsushita20170721}.
\par
Understanding how NLPSO detection of saddle-node bifurcation works requires understanding of the Particle Swarm Optimization (PSO).
PSO is a popular population-based evolutionary algorithm.
It tracks several particles which represent potential solution.
Each particle has its own position and velocity. It also tracks its previous best position and score.
Each particle moves through the search space based on its velocity and position.
Its movement is also influenced by its previous best position and the best positions of other particles.~\cite{Matsushita2019}
\par
Each particle has a position $pos \in \mathbb{R}^{n}$, a velocity $vel \in \mathbb{R}^{n}$, a best position $b_{pos} \in \mathbb{R}^{n}$ and a best score $b_{score} \in \mathbb{R}$.
The algorithm also tracks global best position $g_{pos}$ and global best score $g_{score}$.
The pseudocode for the PSO algorithm is given in Algorithm~\ref{alg:pso}.
Parameters in Algorithm~\ref{alg:pso} $w$, $c_{1}$ and $c_{2}$ shall be set as $w=0.729$ and $c_{1}=c_{2}=1.494$~\cite{Matsushita2019}.

\begin{algorithm}[!h]
    \caption{Particle Swarm Optimization (PSO)}
    \label{alg:pso}
    \begin{algorithmic}[1]
        \Statex $f \gets$ function to minimize, $f: \mathbb{R}^{m} \rightarrow \mathbb{R}$.
        \Statex $(a, b) \gets$ search-space range
        \Statex $n \gets$ number of particles
        \Statex $maxiter \gets$ maximum number of iterations
        \Statex $tol \gets$ tolerance for determining solution
        \Statex $w, c_{1}, c_{2} \gets$ parameters described in the text
        \State Create $n$ particles.
        \For{each particle}
            \State $pos$ $m$-dimensional vector of uniform random numbers between $a$ and $b$.
            \State $vel$ $m$-dimensional zero vector.
            \State $b_{pos} \gets$ $m$-dimensional vector of uniform random numbers between $a$ and $b$.
            \State $b_{score} \gets \infty$
        \EndFor
        \State $g_{pos}$ $m$-dimensional vector of uniform random numbers between $a$ and $b$.
        \State $g_{score} \gets \infty$

        \For{iteration less than $maxiter$}
            \For{each particle}
                \State $score \gets f(pos)$ 
                \If{$score < b_{score}$}
                    \State $b_{score} \gets score$
                    \State $b_{pos} \gets pos$
                \EndIf
                \If{$score < g_{score}$}
                    \State $g_{score} \gets score$
                    \State $g_{pos} \gets pos$
                \EndIf
            \EndFor
            \If{$g_{score} < tol$}
                \State break the loop
            \EndIf
            \For{each particle}
                \State $r_{1}, r_{2} \gets$ random numbers between $0$ and $1$.
                \State $vel \gets w(vel) + c_{1}r_{1}(b_{pos}-pos) + c_{2}r_{2}(g_{pos}-pos)$
                \State $pos \gets pos + vel$
            \EndFor
        \EndFor
    \end{algorithmic}
\end{algorithm}

\par
The next step is to combine two PSOs.
One of them will be looking for a parameter $p_b$ at which saddle-node bifurcation occurs.
The other one will be looking for periodic point $x_b$ corresponding to $p_b$.
Each PSO requires a function that is to be minimized.
Its worth noticing that the algorithm works for dynamical systems of arbitrary dimensions.
For that reason the minimization functions are presented in a general form.
\par
Let $(\mathbb{R}^{m}, f)$ be a DDS.
Search for a periodic point $x_0$ for an arbitrary parameter $p$ is performed.
After selecting parameter $p$, a search for a periodic point $x_0$ is performed by minimizing the function $F_{loss}(x_0) = \norm{f^{n}_{p}(x_0)-x_0}$.
If $x_0$ is a fixed point of $f^{n}_{p}$ then $x_0$ is an $n$-periodic point of $f$.
It is a fixed point in case $f^{n}_{p}(x_0)-x_0 = 0$.
Hence, minimizing the $F_{loss}$ brings us closer to the $n$-periodic point.
PSO can be used to search for an optimal parameter $x_0$ by minimizing $F_{loss}$.
\par
A search for parameter $p_b$ at which saddle-node bifurcation occurs is performed.
Saddle-node bifurcation occurs at parameter $p$ when the characteristic equation $G_{loss}(p) = \text{det}(Df^{n}_{p}(x_0)-\mu I)$ is equal to $0$, $x_0$ is $n$-periodic point and parameter $\mu = 1$.
\par
Hence, minimization of $G_{loss}(p) = |\text{det}(Df^{n}_{p}(x_0)-\mu I)|$ for different parameters $p$ would yield saddle-node bifurcation parameter $p_b$.
However, in order to evaluate $G_{loss}$ it is needed to know $x_0$ which is currently unknown.
Thus, a PSO can be used for minimizing $F_{loss}(x_{0})$ to find $x_0$ and use $p_0$ as a system parameter that was described in the previous paragraph.
It is important to be sure that found point $x_0$ is $n$-periodic point and thus $G_{loss}$ is only evaluated if PSO converged correctly to $x_0$.
Updated function $G_{loss}$ is presented in Equation~\eqref{eq:minimize_p} and is now called $H_{loss}$.
Thus, minimizing the function $H_{loss}$ from Equation~\eqref{eq:minimize_p} by PSO finds optimal parameter $p_b$.

\begin{equation}
\label{eq:minimize_p}
    H_{loss}(p) =
    \begin{cases}
        |\text{det}(Df^{n}_{p}(x_0)-\mu I)| & \text{if } F_{loss}(x_0) < C_{pp}, \\
        \infty & \rm{otherwise}
    \end{cases}
\end{equation}

\par
The previous paragraphs described how to use the two types of PSOs.
The main PSO looks for parameter $p_b$ at which saddle-node bifurcation occurs.
It does so by minimizing function $H_{loss}$ from~\eqref{eq:minimize_p}.
During every evaluation of $H_{loss}$ at parameter $p_0$ it is needed to find $x_0$ which is $n$-periodic point of $f^{n}_{p_0}$.
That can be achieved by using the second nested PSO which minimizes function $F_{loss}$ by using $p_0$ as parameter in $F_{loss}$.
This nesting of PSOs is the reason why this algorithm is called Nested-Layer Particle Swarm Optimization.
Period $n$ is the same in both functions $F_{loss}$ and $H_{loss}$.
It corresponds to the period of the system at the saddle-node bifurcation.
Fortunately the parameter $n$ is known from the global search.
Parameter range $(p_A, p_B)$ is also known from the global search and is used in the top-level PSO as search-space range.
The search-space range used for the nested PSO is also known.
It is because the system is invariant under some set.
For example for the Logistic equation, the search-space range can be set to $[0, 1]$.

\subsection{Local Search using Global Optimization}
The previous subsection introduced the NLPSO algorithm for finding saddle-node bifurcations.
It achieves its goal by formulating the problem as an optimization problem and by nesting two optimization algorithms into each other.
However, there exists another approach which also uses global optimization approach.
This approach shall be called Local Search using Global Optimization (LSGO).
\par
The LSGO approach formulates the saddle-node bifurcation detection as an optimization problem.
However, it uses different formulation that the NLPSO.
As mentioned earlier, detecting saddle-node bifurcations helps to find the regions exhibiting the type-I intermittency.
\par
The LSGO uses the following formulation:
\begin{align*} 
x_0 &= f_{p}^{n}(x_0)\\
x_1 &= f_{p}^{n}(x_1)\\
\vdots \\
x_n &= f_{p}^{n}(x_n)\\
\end{align*}

In the presented formulation $x_0$ is an $n$-periodic point of $f_{p}$.
Hence, there are $n$ equations of the form $x_i = f_{p}^{n}(x_i)$ which hold.
These equations can further be formulated to depend only on the parameter $p$ and point $x_0$.

\begin{align*} 
f_{p}^{0}(x_0) &= f_{p}^{n}(f_{p}^{0}(x_0)) \\
f_{p}^{1}(x_0) &= f_{p}^{n}(f_{p}^{1}(x_0)) \\
\vdots \\
f_{p}^{n}(x_0) &= f_{p}^{n}(f_{p}^{n}(x_0)) \\
\end{align*}

Furthermore, if $p$ is a saddle-node bifurcation parameter then for all $\{ x_{i}: i \in [1, n] \}$ it holds $(f_{p}^{n})'(x_i) = 1$, in one dimensional case.
Thus, these $n$ equations hold:

\begin{align*} 
(f_{p}^{n})'(f_{p}^{0}(x_0)) &= 1 \\
(f_{p}^{n})'(f_{p}^{1}(x_0)) &= 1 \\
\vdots \\
(f_{p}^{n})'(f_{p}^{n}(x_0)) &= 1 \\
\end{align*}

Combining all these equations yields a system of $2n$ equations.
Putting all terms on one side results in:

\begin{equation}
\label{eq:full_system}
\begin{aligned} 
f_{p}^{n}(f_{p}^{0}(x_0)) - f_{p}^{0}(x_0) &= 0 \\
f_{p}^{n}(f_{p}^{1}(x_0)) - f_{p}^{1}(x_0) &= 0 \\
\vdots \\
f_{p}^{n}(f_{p}^{n}(x_0)) - f_{p}^{n}(x_0) &= 0 \\
(f_{p}^{n})'(f_{p}^{0}(x_0)) - 1 &= 0 \\
(f_{p}^{n})'(f_{p}^{1}(x_0)) - 1 &= 0 \\
\vdots \\
(f_{p}^{n})'(f_{p}^{n}(x_0)) - 1 &= 0 \\
\end{aligned}
\end{equation}

Finding analytical solution to the system of equations~\eqref{eq:full_system} would yield $p$ at which the saddle-node bifurcation occurs.
Additionally, $x_0$ would be found as well and could be used to retrieve the whole periodic orbit.
However, finding analytical solution might not be possible and feasible.
Using tools from theory of optimization might be a better approach.
\par
Let's define a function $H: \mathbb{R}^{2} \rightarrow \mathbb{R}$ as follows:

\begin{multline*} 
H(p, x_0) = (f_{p}^{n}(f_{p}^{0}(x_0)) - f_{p}^{0}(x_0))^2 + \dots + (f_{p}^{n}(f_{p}^{n}(x_0)) - f_{p}^{n}(x_0))^2 + \\
    + ((f_{p}^{n})'(f_{p}^{0}(x_0)) -1)^2 + \dots + ((f_{p}^{n})'(f_{p}^{n}(x_0)) -1)^2
\end{multline*}

Function $H$ has global minimum of $0$ at point $(p, x_0) \in \mathbb{R}^{2}$.
By minimizing this function, such point can be found.
By setting tolerance criterion for the minimization algorithm low enough, it can be decided whether $p$ is indeed a parameter of saddle-node bifurcation or not.
\par
Note that the search space might not be the whole $\mathbb{R}^{2}$.
For instance in the case of the Logistic map the search space is $[0, 4] \times [0, 1]$ since $p \in [0,4]$ and $x \in [0,1]$.
However, the search space can be reduced even further.
The global search has already identified the intervals $[p_A, p_B]$ in the parameter space where the saddle-node bifurcation occurs.
Hence, the search space can be reduced to $[p_A, p_B] \times [0, 1]$.
If the optimization converges with enough precision, then it can be supposed that the parameter at which the breakpoint occurs has been found.
\par
Furthermore, note that different types of optimization algorithms can be used.
For example, the Particle Swarm Optimization (PSO) algorithm described earlier can be used.
In our implementation we used the Evolutionary Centers Algorithm~\cite{MejiadeDios20190913} which has proven to be the most effective.

\section{Coloring}
The goal of this phase is to color the neighborhood of the breakpoint to warn about its ambiguity.
Parameters at which the breakpoint occurs were found in the previous steps.
Theory of type-I intermittency is used to color the neighborhood of the breakpoint.

\subsection{Description of the algorithm}
The local search finds parameters of the parameter space at which the breakpoint occurs.
Let $p_b$ be one of them.
It is known that parameters to the left side $p_b$ in its proximity exhibit intermittency.
Nevertheless, there is a need to quantify how far from $p_b$ is intermittency still occurring.
Additionally, it is needed to measure how prominent the intermittency is for some $p$ near $p_b$.
\par
A useful indicator about the intermittent behavior is average laminar length $l_{avg}$ described in Chapter~\ref{chap:type-I intermittency}.
The characteristic relation $l_{avg} \varpropto 1 / \sqrt{\varepsilon}$ can be used to estimate the average laminar length.
Characteristic relation is dependent on the local map around fixed points associated with saddle-node bifurcation.
Fortunately, these fixed point have been found in the local search.
Hence, by calculating $\varepsilon$ for each stable fixed point of $f_{p_b}$, $l_{avg}$ can be estimated for laminar region around each fixed point.
Taking their average yields an estimation of the average laminar length for $p_b$.
\par
Depending on the parameter $p$ the laminar phases have various lengths.
Far to the left of $p_b$ the laminar phases are about $50$ iterations long.
Very close to the left of $p_b$ the length of the laminar phase can get arbitrary long.
The closer the parameter $p$ gets to $p_b$ the longer the laminar phase gets.
\par
To colorize the diagram it is needed to determine the average laminar length for the parameters $p$ to the left of $p_b$ and to compare them.
However, the average laminar lengths can get arbitrary large.
It is convenient to color only parameters $p$ that have average laminar lengths between $L$ and $U$. 
$L$ denotes the lower bound and $U$ denotes the upper bound.
For example $L$ can be set to $100$ and $U$ to $1000$.
The next step is to find parameters $p_L$ and $p_U$ such that parameters $p$ between $p_L$ and $p_U$ have $l_{avg}$ from range $[ L, U ]$.
\par
The idea behind an algorithm to find $p_L$ and $p_U$ is to step to the left from $p_b$ with incrementally smaller steps.
The algorithm is illustrated in Algorithm~\ref{alg:optimal_bound}.

\begin{algorithm}[!h]
    \caption{Optimal bound search}
    \label{alg:optimal_bound}
    \begin{algorithmic}[1]
        \Statex $f \gets$ map
        \Statex $p \gets$ initial bound estimate
        \Statex $s \gets$ step
        \Statex $B \gets$ desired average laminar length
        \Statex $t \gets$ $B$ deviation tolerance
        \Statex $i_{m} \gets$ maximum of iterations
        \Statex $i_{c} \gets$ current iteration

        \For{$i$ from $i_{c}$ to $i_{m}$}
            \State $p \gets p - s$
            \State $l_{avg} \gets$ average laminar length for $p$
            \If{$B-t \leq l_{avg} \leq B+t$}
                \State Terminate program with $p$ as the optimal bound.
            \EndIf
            \If{$l_{avg} < B-t$}
                \State Repeat the program for $p = p+s$, $s = s/2$ and $i_{c} = i+1$. The rest of the parameters remain unchanged.
            \EndIf
        \EndFor
    \end{algorithmic}
\end{algorithm}

The Algorithm~\ref{alg:optimal_bound} can be used for finding both $p_L$ and $p_U$.
The algorithm can be started with $p = p_b$, $s = 0.1$, $i_{m} = 200$, $i_{c} = 0$, $t = 10$.
For finding $p_L$, initial bound estimate $B = 100$.
For finding $p_U$, initial bound estimate $B = 1000$.
This way both $p_L$ and $p_U$ is obtained.
\par
To finish the coloring procedure, bifurcation diagram is constructed.
A color range is defined for numbers in range $[ l_{avg}$ for $p_L, l_{avg}$ for $p_U ]$.
The trajectory projections for parameters $p \in [ p_L, p_U ]$ are colored using this color range.
The same coloring procedure is repeated for all breakpoint parameters found in the local search.
\par
The result of the coloring algorithm for the Logistic map is shown in Figure~\ref{fig:coloring_example}.
Note that when the parameter space is large, the coloring of individual breakpoint is not very useful.
However, the user can always zoom in to the breakpoint if needed and then the coloring becomes useful.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{Figures/logistic_map_coloring_example.png}
    \caption{
        \textcolor{darkred}{
        Colorization of a single breakpoint of $\mathcal{L}_{r}$ for $r \in I := [ 3.6263, 3.6267 ]$.
        Algorithm~\ref{alg:optimal_bound} was used to specify the colorization bounds.
        The bifurcation diagram consists of projections $\mathcal{T}_{900}^{1000}(\mathcal{L}_{r}, 0.5)$ for $r \in I$.
        }
    }
    \label{fig:coloring_example}
\end{figure}

\section{Complete Algorithm}
In the previous sections each part of the algorithm was described.
It was also pointed out how each part of the algorithm relates to the other parts.
For clarity, this section explains how to combine all the parts together.
\par
First, the Global search is used to identify intervals where breakpoint could occur.
Secondly, the Local search is employed for each of the intervals to find precise parameter, periodicity and the fixed points of the breakpoint.
Three alternatives for the Local search were introduced.
Any one of them can be used.
Lastly, areas next to the found breakpoint are colored using the Coloring method.
The result is a bifurcation diagram with identified breakpoint whose left neighborhoods are colored.
\par
An example of the complete algorithm is shown in Figure~\ref{fig:complete_colorization}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.95\textwidth]{Figures/complete_colorization.png}
    \caption{
        \textcolor{darkred}{
        Full Colorization of $\mathcal{L}_{r}$ for $r \in [ 3.62, 3.65 ]$.
        The bifurcation diagram consists of projections of $\mathcal{T}_{900}^{1000}(\mathcal{L}_{r}, 0.5)$.
        Colorful lines: areas near the detected breakpoints (up to period $20$).
        }
    }
    \label{fig:complete_colorization}
\end{figure}

\endinput